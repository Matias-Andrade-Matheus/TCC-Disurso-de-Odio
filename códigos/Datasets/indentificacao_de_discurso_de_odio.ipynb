{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "t2hZ_vC69_al"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randrange\n",
        "from wordcloud import WordCloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lHsWoEtg-IU5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Baixar recursos do NLTK (se necessário)\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "stop_words = stopwords.words('portuguese')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DVr6Ai7GPzca"
      },
      "outputs": [],
      "source": [
        "stopwords_especificas = [\n",
        "    \"vc\", \"voce\", \"vcs\", \"tá\", \"ta\", \"to\", \"tô\", \"pq\", \"q\", \"né\", \"eh\", \"ai\", \"aí\", \"c\", \"d\", \"já\",\n",
        "    \"pro\", \"pra\", \"pras\", \"nois\", \"tbm\", \"tb\", \"que\", \"oq\", \"ctz\", \"td\", \"toda\", \"todo\", \"todos\", \"ja\",\n",
        "    \"ate\", \"até\", \"dps\", \"qdo\", \"cm\", \"rt\", \"from\", \"rs\", \"aff\", \"dae\", \"dai\", \"so\", \"só\", \"la\", \"lá\",\"cade\",\n",
        "    \"xq\", \"x\", \"tam\", \"vlw\", \"obg\", \"ne\", \"n\", \"ñ\", \"nn\", \"nao\", \"sim\", \"s\", \"ss\", \"pfv\", \"pf\", \"plz\",\n",
        "    \"cadê\", \"kd\", \"aki\", \"aqui\", \"ali\", \"dali\", \"naquele\", \"naquela\", \"naquilo\", \"aonde\", \"dela\", \"dele\",\n",
        "    \"deles\", \"delas\", \"mt\", \"mto\", \"mtos\", \"mta\", \"mtas\", \"oh\", \"ah\", \"ui\", \"ops\", \"lol\", \"ftw\",\n",
        "    \"oxe\", \"argh\", \"eita\", \"ih\", \"ui\", \"epa\", \"oba\", \"ufa\", \"aham\", \"hmm\", \"hm\", \"hi\", \"hein\", \"puf\",\n",
        "    \"tipo\", \"tipo assim\", \"mano\", \"cara\", \"vei\", \"gente\", \"galera\", \"fia\", \"fi\", \"tamo\", \"vamo\", \"bora\",\n",
        "    \"sao\", \"vai\", \"vem\", \"aonde\", \"donde\", \"onde\", \"aqui\", \"dali\", \"ma\", \"meu\", \"minha\", \"nosso\", \"nossa\"\n",
        "]\n",
        "\n",
        "abrevicoes_odiosas = [\n",
        "    \"wtf\", \"pqp\", \"vsfd\", \"sfd\", \"vtmnc\", \"vtmc\", \"tmnk\", \"tmnc\", \"fdp\", \"fds\", \"k7\", \"kct\", \"prr\", \"mrda\", \"merd\", \"mrd\", \"bct\", \"pk\", \"xt\", \"krl\",\n",
        "    \"crl\", \"bct\", \"bp\", \"nc\", \"vdd\", \"viad\", \"vyd\", \"bait\", \"beyt\", \"bixa\", \"bixy\", \"bixa\", \"bixy\", \"fudr\", \"fodr\", \"fodase\", \"crlh\", \"crl\", \"caralh\",\n",
        "    \"carlh\", \"porr\", \"p0rr4\", \"p0rr@\", \"fuder\", \"fud3r\", \"f0d3r\", \"f0der\", \"mcl\", \"m3rd4\", \"m3rd@\", \"merd4\", \"merd@\", \"bocet\", \"b0cet\", \"boc3t\", \"b0c3t\",\n",
        "    \"bucet\", \"buc3t\", \"b0cet\", \"b0c3t\", \"pint0\", \"pint@\", \"p1nt@\", \"p1nt0\", \"rola\", \"r0l@\", \"r0l4\", \"rol4\", \"rol@\", \"vagabund\", \"vagabund@\", \"vagabund4\", \"vagabund0\",\n",
        "    \"vgbd\",\"vadia\", \"vadi4\", \"vadi@\", \"v4di@\", \"v4di4\", \"puta\", \"put4\", \"put@\", \"dbf\", \"aut\", \"rtd\", \"cuz4o\", \"cuz@o\", \"cuz4@\", \"cuz@\", \"stpr\"\n",
        "]\n",
        "    \n",
        "abrevicoes_odiosas = set(abrevicoes_odiosas)\n",
        "\n",
        "stopwords_tradicionais = set(stop_words)\n",
        "\n",
        "stopwords_especificas = set(stopwords_especificas)\n",
        "\n",
        "STOPWORDS_COMPLETA = stopwords_tradicionais.union(stopwords_especificas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "M7drhy0rpDoB"
      },
      "outputs": [],
      "source": [
        "def remover_palavras_exatas(texto: str, palavras: list[str]) -> str:\n",
        "    \"\"\"\n",
        "    Remove palavras exatas do texto usando regex, sem remover substrings.\n",
        "\n",
        "    Args:\n",
        "        texto (str): Texto de entrada.\n",
        "        palavras (list[str]): Lista de palavras a remover (exatamente).\n",
        "\n",
        "    Returns:\n",
        "        str: Texto com as palavras removidas.\n",
        "    \"\"\"\n",
        "    for palavra in palavras:\n",
        "        # Remove a palavra com delimitador de palavra (\\b) e insensível a maiúsculas\n",
        "        padrao = rf'\\b{re.escape(palavra)}\\b'\n",
        "        texto = re.sub(padrao, '', texto, flags=re.IGNORECASE)\n",
        "\n",
        "    # Limpa múltiplos espaços e espaços antes de pontuação\n",
        "    texto = re.sub(r'\\s{2,}', ' ', texto)\n",
        "    texto = re.sub(r'\\s+([,.!?;:])', r'\\1', texto)\n",
        "\n",
        "    return texto.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YVnQ7wyY-V77"
      },
      "outputs": [],
      "source": [
        "# 2. Pré-processamento (corrigido) [99%]\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def clean_text(text, lemmatizer=False):\n",
        "    '''\n",
        "    Perform stop-words removal and lemmatization\n",
        "    '''\n",
        "\n",
        "    text = str(text)\n",
        "\n",
        "    if lemmatizer:\n",
        "        words = [word for word in text.split()]\n",
        "        words = [WordNetLemmatizer().lemmatize(word) for word in words]\n",
        "        return \" \".join(words)\n",
        "    \n",
        "    text = text.lower()\n",
        "\n",
        "    text_normalize = unicodedata.normalize(\"NFKD\", text)\n",
        "    text = ''.join(\n",
        "        char for char in text_normalize\n",
        "        if not unicodedata.combining(char)\n",
        "    )\n",
        "\n",
        "    text = text.encode('ascii', 'ignore').decode('utf-8')\n",
        "\n",
        "    words = text.split()\n",
        "    for word in words:\n",
        "        if re.search('http', word) or re.search('https', word):\n",
        "            text = text.replace(word, '')\n",
        "\n",
        "        if re.search('@', word) or re.search('#', word):\n",
        "            text = text.replace(word, '')\n",
        "\n",
        "        if re.search('kk', word) or re.search(\"hah\", word) or re.search('aha', word):\n",
        "            text = text.replace(word, '')\n",
        "\n",
        "        if word in abrevicoes_odiosas:\n",
        "            for abrev in abrevicoes_odiosas:\n",
        "                if re.search(abrev, word) and len(abrev) == len(word):\n",
        "                    text = text.replace(abrev, 'KKK')\n",
        "                \n",
        "\n",
        "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", text)\n",
        "    words = [word for word in text.split() if (word not in STOPWORDS_COMPLETA)]\n",
        "\n",
        "\n",
        "    return \" \".join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Criação de Datasets limpos\n",
        "import os\n",
        "import re\n",
        "\n",
        "pasta_atual = os.getcwd()\n",
        "if os.path.exists(pasta_atual+\"/Datasets\"):\n",
        "    pasta_datasets_sujos = os.path.join(pasta_atual, \"Datasets\")\n",
        "    datasets_paths = []\n",
        "\n",
        "    if os.path.exists(pasta_datasets_sujos+\"/OLID - BR\"):\n",
        "        pasta_olid = os.path.join       (pasta_datasets_sujos, \"OLID - BR\")\n",
        "        arquivo_olid = os.path.join(pasta_olid, \"2019-05-28_portuguese_hate_speech_binary_classification.csv\")\n",
        "        datasets_paths.append(arquivo_olid)\n",
        "\n",
        "    if os.path.exists(pasta_datasets_sujos+\"/OffComBR-3\"):\n",
        "        pasta_offcomTres = os.path.join(pasta_datasets_sujos, \"OffComBR-3\")\n",
        "        arquivo_offcomTres = os.path.join(pasta_offcomTres, \"OffComBR3.csv\")\n",
        "        datasets_paths.append(arquivo_offcomTres)\n",
        "\n",
        "    if os.path.exists(pasta_datasets_sujos+\"/Offcom2\"):\n",
        "        pasta_offcomDois = os.path.join   (pasta_datasets_sujos, \"Offcom2\")\n",
        "        arquivo_offcomDois = os.path.join(pasta_offcomDois, \"OffComBR2.csv\")\n",
        "        datasets_paths.append(arquivo_offcomDois)\n",
        "\n",
        "    if os.path.exists(pasta_datasets_sujos+\"/ToLD\"):\n",
        "        pasta_told = os.path.join            (pasta_datasets_sujos, \"ToLD\")\n",
        "        arquivo_told = os.path.join(pasta_told, \"ToLD-BR_binario.csv\")\n",
        "        datasets_paths.append(arquivo_told)\n",
        "\n",
        "    if os.path.exists(pasta_datasets_sujos+\"/hateBR\"):\n",
        "        pasta_hate = os.path.join          (pasta_datasets_sujos, \"hateBR\")\n",
        "        arquivo_hate = os.path.join(pasta_hate, \"HateBR.csv\")\n",
        "        datasets_paths.append(arquivo_hate)\n",
        "    \n",
        "    # multioffcom3\n",
        "    if os.path.exists(pasta_datasets_sujos+\"/OffComBR-3\"):\n",
        "        pasta_multiOffcomTres = os.path.join(pasta_datasets_sujos, \"OffComBR-3\")\n",
        "        arquivo_multiOffcomTres = os.path.join(pasta_multiOffcomTres, \"MultiOffComBR3.csv\")\n",
        "        datasets_paths.append(arquivo_multiOffcomTres)\n",
        "\n",
        "text=['text','mensagem','comentario','text','comentario']\n",
        "label = ['hatespeech_comb','label','label','Discurso_de_odio','label_final']\n",
        "\n",
        "if not os.path.exists(\"Datasets Limpos\"):\n",
        "    os.mkdir(\"Datasets Limpos\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "8p4A3QSFo0qb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coleção de dados : 2019-05-28_portuguese_hate_speech_binary_classification.csv\n",
            "Shape : (5670, 8)\n",
            "Instâncias : hatespeech_comb\n",
            "0    3882\n",
            "1    1788\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Coleção de dados : OffComBR3.csv\n",
            "Shape : (1033, 2)\n",
            "Instâncias : label\n",
            "no     831\n",
            "yes    202\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Coleção de dados : OffComBR2.csv\n",
            "Shape : (1250, 2)\n",
            "Instâncias : label\n",
            "no     831\n",
            "yes    419\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Coleção de dados : ToLD-BR_binario.csv\n",
            "Shape : (21000, 15)\n",
            "Instâncias : Discurso_de_odio\n",
            "0    11742\n",
            "1     9258\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Coleção de dados : HateBR.csv\n",
            "Shape : (7000, 8)\n",
            "Instâncias : label_final\n",
            "1    3500\n",
            "0    3500\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "datasets = [\n",
        "    'Datasets/OLID - BR/2019-05-28_portuguese_hate_speech_binary_classification.csv',\n",
        "    'Datasets/OffComBR-3/OffComBR3.csv',\n",
        "    'Datasets/Offcom2/OffComBR2.csv',\n",
        "    'Datasets/ToLD/ToLD-BR_binario.csv',\n",
        "    'Datasets/hateBR/HateBR.csv'\n",
        "]\n",
        "\n",
        "text=['text','mensagem','comentario','text','comentario']\n",
        "label = ['hatespeech_comb','label','label','Discurso_de_odio','label_final']\n",
        "for dataset,label in zip(datasets,label) :\n",
        "  df = pd.read_csv(dataset)\n",
        "  print(\"Coleção de dados : {}\\nShape : {}\\nInstâncias : {}\\n\\n\".format(\n",
        "      dataset.split('/')[-1],\n",
        "      df.shape,\n",
        "      df[label].value_counts()\n",
        "      ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "kmKEzQIV4rZ6",
        "outputId": "54241476-e4ed-4a82-ee14-1321371404e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Texto Original : RT @pauloap: Porra, olha a série de reportagens que o Jornal da Record estreia hoje, nunca que a Globo faria https://t.co/1QzI4oabRD\n",
            "Texto Limpo : porra olha serie reportagens jornal record estreia hoje nunca globo faria\n",
            "Texto Limpo e Lemmatizado : RT @pauloap: Porra, olha a série de reportagens que o Jornal da Record estreia hoje, nunca que a Globo faria https://t.co/1QzI4oabRD\n",
            "\n",
            "\n",
            "Texto Original : 'O que esta OPOSICAO esta conseguindo e atrair para si e para os proximos e o odio dos eleitores '\n",
            "Texto Limpo : oposicao conseguindo atrair si proximos odio eleitores\n",
            "Texto Limpo e Lemmatizado : 'O que esta OPOSICAO esta conseguindo e atrair para si e para o proximos e o odio do eleitores '\n",
            "\n",
            "\n",
            "Texto Original : 'Um volante da base PELO AMOR DE DEUS para o lugar de Marcio AraujoPELA AMOR'\n",
            "Texto Limpo : volante base amor deus lugar marcio araujopela amor\n",
            "Texto Limpo e Lemmatizado : 'Um volante da base PELO AMOR DE DEUS para o lugar de Marcio AraujoPELA AMOR'\n",
            "\n",
            "\n",
            "Texto Original : rt @user vejo a ana e a chai mais do que a minha família\n",
            "Texto Limpo : vejo ana chai familia\n",
            "Texto Limpo e Lemmatizado : rt @user vejo a ana e a chai mais do que a minha família\n",
            "\n",
            "\n",
            "Texto Original : Mostro sempre Benedita falando para minhas filhas branquinhas... quero beneditas ao meu redor!!!! Fora racistas.!!!!\n",
            "Texto Limpo : mostro sempre benedita falando filhas branquinhas quero beneditas redor racistas\n",
            "Texto Limpo e Lemmatizado : Mostro sempre Benedita falando para minhas filhas branquinhas... quero beneditas ao meu redor!!!! Fora racistas.!!!!\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "for text_,dataset in zip(text,datasets):\n",
        "  df = pd.read_csv(dataset)\n",
        "  texto = df[text_]\n",
        "  texto = texto[random.randrange(len(df))]\n",
        "  limpo = clean_text(texto)\n",
        "  lemmatizado = clean_text(texto, lemmatizer=True)\n",
        "  print(\"Texto Original : {}\\nTexto Limpo : {}\\nTexto Limpo e Lemmatizado : {}\\n\\n\".format(texto,limpo,lemmatizado))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      Dataset  # Instâncias  Tamanho Médio (palavras)  \\\n",
            "0   OLID - BR          5670                     15.81   \n",
            "1  OffComBR-3          1033                     13.70   \n",
            "2     Offcom2          1250                     13.21   \n",
            "3        ToLD         21000                     15.62   \n",
            "4      hateBR          7000                     13.93   \n",
            "\n",
            "   Tamanho Médio (caracteres)  # Classes Distribuição de Classes  \n",
            "0                      101.35          2        0: 3882, 1: 1788  \n",
            "1                       77.21          2       no: 831, yes: 202  \n",
            "2                       74.56          2       no: 831, yes: 419  \n",
            "3                       87.02          2       0: 11742, 1: 9258  \n",
            "4                       81.96          2        1: 3500, 0: 3500  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Lista de datasets e suas respectivas colunas\n",
        "datasets = [\n",
        "    'Datasets/OLID - BR/2019-05-28_portuguese_hate_speech_binary_classification.csv',\n",
        "    'Datasets/OffComBR-3/OffComBR3.csv',\n",
        "    'Datasets/Offcom2/OffComBR2.csv',\n",
        "    'Datasets/ToLD/ToLD-BR_binario.csv',\n",
        "    'Datasets/hateBR/HateBR.csv'\n",
        "]\n",
        "\n",
        "text_columns = ['text', 'mensagem', 'comentario', 'text', 'comentario']\n",
        "label_columns = ['hatespeech_comb', 'label', 'label', 'Discurso_de_odio', 'label_final']\n",
        "\n",
        "results = []\n",
        "try:\n",
        "    # Ler o dataset para criação Global\n",
        "    df = pd.read_csv(datasets[0])\n",
        "except Exception as e:\n",
        "    print(f\"Erro ao processar {dataset[0]}: {str(e)}\")\n",
        "\n",
        "for i, dataset_path in enumerate(datasets):\n",
        "    try:\n",
        "        # Ler o dataset\n",
        "        df = pd.read_csv(dataset_path)\n",
        "        \n",
        "        # Obter colunas de texto e label\n",
        "        text_col = text_columns[i]\n",
        "        label_col = label_columns[i]\n",
        "        \n",
        "        # Calcular estatísticas\n",
        "        num_instances = len(df)\n",
        "        \n",
        "        # Tamanho médio em palavras\n",
        "        avg_word_length = df[text_col].apply(lambda x: len(str(x).split())).mean()\n",
        "        \n",
        "        # Tamanho médio em caracteres\n",
        "        avg_char_length = df[text_col].apply(lambda x: len(str(x))).mean()\n",
        "        \n",
        "        # Número de classes\n",
        "        num_classes = df[label_col].nunique()\n",
        "        \n",
        "        # Distribuição de classes\n",
        "        class_distribution = df[label_col].value_counts().to_dict()\n",
        "        \n",
        "        # Formatar distribuição para melhor visualização\n",
        "        dist_str = \", \".join([f\"{k}: {v}\" for k, v in class_distribution.items()])\n",
        "        \n",
        "        results.append({\n",
        "            'Dataset': dataset_path.split('/')[1],\n",
        "            '# Instâncias': num_instances,\n",
        "            'Tamanho Médio (palavras)': round(avg_word_length, 2),\n",
        "            'Tamanho Médio (caracteres)': round(avg_char_length, 2),\n",
        "            '# Classes': num_classes,\n",
        "            'Distribuição de Classes': dist_str\n",
        "        })\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao processar {dataset_path}: {str(e)}\")\n",
        "\n",
        "# Criar DataFrame com resultados\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n",
        "\n",
        "# Salvar resultados em CSV\n",
        "# results_df.to_csv('estatisticas_datasets.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KRfxKpQWFcd_"
      },
      "outputs": [],
      "source": [
        "# 2.1. Data Frame Treatment & Training and Matching Separation\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_and_prepare_data(filepath, text_colum, label_colum):\n",
        "    \"\"\"Carrega e prepara os dados\"\"\"\n",
        "    # Carregar dados\n",
        "    df_TextLabel = pd.read_csv(filepath)\n",
        "\n",
        "    # Limpar textos\n",
        "    df_TextLabel['cleaned_text'] = df_TextLabel[text_colum].apply(clean_text)\n",
        "\n",
        "    # Filtrar colunas necessárias\n",
        "    df_TextLabel = df_TextLabel[['cleaned_text', label_colum]]\n",
        "    df_TextLabel.columns = ['text', 'label']\n",
        "\n",
        "    # Remover linhas vazias\n",
        "    df_TextLabel = df_TextLabel.dropna()\n",
        "    df_TextLabel = df_TextLabel[df_TextLabel['text'] != '']\n",
        "\n",
        "    return df_TextLabel\n",
        "\n",
        "def split_data(df_TextLabel):\n",
        "    \"\"\"Divide os dados em treino e teste\"\"\"\n",
        "    text_var = df_TextLabel['text']\n",
        "    label_var = df_TextLabel['label']\n",
        "    return train_test_split(text_var, label_var, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4BQCCoFGFpS"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'label'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyError\u001b[39m: 'label'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m classes = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.unique()\n\u001b[32m      7\u001b[39m random_class = classes[randrange(\u001b[38;5;28mlen\u001b[39m(classes))]\n\u001b[32m      9\u001b[39m class_text = \u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m.join(df[df[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m] == random_class][\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m])\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\frame.py:4107\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4107\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4108\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4109\u001b[39m     indexer = [indexer]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
            "\u001b[31mKeyError\u001b[39m: 'label'"
          ]
        }
      ],
      "source": [
        "# 2.2.1. Data Exploration & Visualization (Word Cloud)\n",
        "import pandas as pd\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv('Datasets/OLID - BR/2019-05-28_portuguese_hate_speech_binary_classification.csv')\n",
        "classes = df['label'].unique()\n",
        "random_class = classes[randrange(len(classes))]\n",
        "\n",
        "class_text = ' '.join(df[df['label'] == random_class]['text'])\n",
        "class_text = ' '.join(df['text'])\n",
        "\n",
        "# Gerar a nuvem de palavras\n",
        "wordcloud = WordCloud(width=800, height=800,\n",
        "                         background_color='black',\n",
        "                         stopwords=\"portuguese\",\n",
        "                         collocations=True).generate(class_text)\n",
        "\n",
        "# Plotar\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title(f'Nuvem de Palavras para Classe: {random_class}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "aOMzKN7RTQqQ",
        "outputId": "6b8c1e1b-f1b3-4cd5-befa-7d65c831d4bc"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'label'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m plt.figure(figsize=(\u001b[32m6\u001b[39m, \u001b[32m4\u001b[39m))\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Contando os textos por categoria e plotando\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcategory_column\u001b[49m\u001b[43m)\u001b[49m.size().sort_values(ascending=\u001b[38;5;28;01mFalse\u001b[39;00m).plot.bar(color=\u001b[33m'\u001b[39m\u001b[33m#1f77b4\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Adicionando título e labels\u001b[39;00m\n\u001b[32m     12\u001b[39m plt.title(\u001b[33m\"\u001b[39m\u001b[33mDistribuição de Textos por Categoria no HateBR\u001b[39m\u001b[33m\"\u001b[39m, pad=\u001b[32m20\u001b[39m, fontsize=\u001b[32m14\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\frame.py:9190\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9187\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9190\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9193\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9195\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9196\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9197\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9198\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9200\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\groupby\\groupby.py:1330\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1327\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1329\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1330\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1338\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1340\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1341\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\core\\groupby\\grouper.py:1043\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1041\u001b[39m         in_axis, level, gpr = \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[32m   1046\u001b[39m     exclusions.add(gpr.key)\n",
            "\u001b[31mKeyError\u001b[39m: 'label'"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 2.2.2. Visualisation (Visualizing word count balance in bar chart) [99%]\n",
        "\n",
        "category_column = \"label\"\n",
        "\n",
        "# Criando o gráfico\n",
        "plt.figure(figsize=(6, 4))\n",
        "\n",
        "# Contando os textos por categoria e plotando\n",
        "df.groupby(category_column).size().sort_values(ascending=False).plot.bar(color='#1f77b4')\n",
        "\n",
        "# Adicionando título e labels\n",
        "plt.title(\"Distribuição de Textos por Categoria no HateBR\", pad=20, fontsize=14)\n",
        "plt.xlabel(\"Categoria\", labelpad=10)\n",
        "plt.ylabel(\"Número de Textos\", labelpad=10)\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "\n",
        "# Ajustando layout para não cortar rótulos\n",
        "plt.tight_layout()\n",
        "\n",
        "# Mostrando o gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "I6pO2Or83pfa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_excel('Datasets/OffComBR-3/Multiclasse - OffComBR3.xlsx')\n",
        "multioffcom = df.copy(True).to_csv('Datasets/OffComBR-3/MultiOffComBR3.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iniciando processo de treinamento e avaliação...\n",
            "\n",
            "==================================================\n",
            "Processando dataset: HateBR\n",
            "==================================================\n",
            "Vectorização concluída\n",
            "\n",
            "Treinando MultinomialNB...\n",
            "  Acurácia: 0.8233\n",
            "  F1-Score: 0.8233\n",
            "\n",
            "Treinando RandomForestClassifier...\n",
            "  Acurácia: 0.8076\n",
            "  F1-Score: 0.8071\n",
            "\n",
            "Treinando LinearSVC...\n",
            "  Acurácia: 0.8190\n",
            "  F1-Score: 0.8188\n",
            "\n",
            "Treinando LogisticRegression...\n",
            "  Acurácia: 0.8069\n",
            "  F1-Score: 0.8066\n",
            "\n",
            "Treinando KNeighborsClassifier...\n",
            "  Acurácia: 0.6860\n",
            "  F1-Score: 0.6855\n",
            "\n",
            "==================================================\n",
            "Processando dataset: Offcom2\n",
            "==================================================\n",
            "Vectorização concluída\n",
            "\n",
            "Treinando MultinomialNB...\n",
            "  Acurácia: 0.6988\n",
            "  F1-Score: 0.6740\n",
            "\n",
            "Treinando RandomForestClassifier...\n",
            "  Acurácia: 0.6345\n",
            "  F1-Score: 0.6477\n",
            "\n",
            "Treinando LinearSVC...\n",
            "  Acurácia: 0.6827\n",
            "  F1-Score: 0.6741\n",
            "\n",
            "Treinando LogisticRegression...\n",
            "  Acurácia: 0.6908\n",
            "  F1-Score: 0.6578\n",
            "\n",
            "Treinando KNeighborsClassifier...\n",
            "  Acurácia: 0.5301\n",
            "  F1-Score: 0.5413\n",
            "\n",
            "==================================================\n",
            "Processando dataset: OffcomBR-3\n",
            "==================================================\n",
            "Vectorização concluída\n",
            "\n",
            "Treinando MultinomialNB...\n",
            "  Acurácia: 0.8204\n",
            "  F1-Score: 0.7522\n",
            "\n",
            "Treinando RandomForestClassifier...\n",
            "  Acurácia: 0.7864\n",
            "  F1-Score: 0.7628\n",
            "\n",
            "Treinando LinearSVC...\n",
            "  Acurácia: 0.8010\n",
            "  F1-Score: 0.7591\n",
            "\n",
            "Treinando LogisticRegression...\n",
            "  Acurácia: 0.8155\n",
            "  F1-Score: 0.7327\n",
            "\n",
            "Treinando KNeighborsClassifier...\n",
            "  Acurácia: 0.7961\n",
            "  F1-Score: 0.7445\n",
            "\n",
            "==================================================\n",
            "Processando dataset: OLID-BR\n",
            "==================================================\n",
            "Vectorização concluída\n",
            "\n",
            "Treinando MultinomialNB...\n",
            "  Acurácia: 0.7432\n",
            "  F1-Score: 0.7083\n",
            "\n",
            "Treinando RandomForestClassifier...\n",
            "  Acurácia: 0.7476\n",
            "  F1-Score: 0.7347\n",
            "\n",
            "Treinando LinearSVC...\n",
            "  Acurácia: 0.7449\n",
            "  F1-Score: 0.7334\n",
            "\n",
            "Treinando LogisticRegression...\n",
            "  Acurácia: 0.7502\n",
            "  F1-Score: 0.7185\n",
            "\n",
            "Treinando KNeighborsClassifier...\n",
            "  Acurácia: 0.7193\n",
            "  F1-Score: 0.6643\n",
            "\n",
            "==================================================\n",
            "Processando dataset: BiToLD\n",
            "==================================================\n",
            "Vectorização concluída\n",
            "\n",
            "Treinando MultinomialNB...\n",
            "  Acurácia: 0.7188\n",
            "  F1-Score: 0.7136\n",
            "\n",
            "Treinando RandomForestClassifier...\n",
            "  Acurácia: 0.7541\n",
            "  F1-Score: 0.7548\n",
            "\n",
            "Treinando LinearSVC...\n",
            "  Acurácia: 0.7192\n",
            "  F1-Score: 0.7177\n",
            "\n",
            "Treinando LogisticRegression...\n",
            "  Acurácia: 0.7397\n",
            "  F1-Score: 0.7358\n",
            "\n",
            "Treinando KNeighborsClassifier...\n",
            "  Acurácia: 0.6245\n",
            "  F1-Score: 0.5856\n",
            "\n",
            "==================================================\n",
            "Processando dataset: MultiOffcomBR-3\n",
            "==================================================\n",
            "Vectorização concluída\n",
            "\n",
            "Treinando MultinomialNB...\n",
            "  Acurácia: 0.8155\n",
            "  F1-Score: 0.7327\n",
            "\n",
            "Treinando RandomForestClassifier...\n",
            "  Acurácia: 0.7718\n",
            "  F1-Score: 0.7290\n",
            "\n",
            "Treinando LinearSVC...\n",
            "  Acurácia: 0.8010\n",
            "  F1-Score: 0.7416\n",
            "\n",
            "Treinando LogisticRegression...\n",
            "  Acurácia: 0.8204\n",
            "  F1-Score: 0.7437\n",
            "\n",
            "Treinando KNeighborsClassifier...\n",
            "  Acurácia: 0.8155\n",
            "  F1-Score: 0.7423\n",
            "\n",
            "\n",
            "============================================================\n",
            "RESUMO FINAL DOS RESULTADOS\n",
            "============================================================\n",
            "\n",
            "Dataset: HateBR\n",
            "----------------------------------------\n",
            "MultinomialNB             | Acurácia: 0.8233 | F1: 0.8233\n",
            "RandomForestClassifier    | Acurácia: 0.8076 | F1: 0.8071\n",
            "LinearSVC                 | Acurácia: 0.8190 | F1: 0.8188\n",
            "LogisticRegression        | Acurácia: 0.8069 | F1: 0.8066\n",
            "KNeighborsClassifier      | Acurácia: 0.6860 | F1: 0.6855\n",
            "\n",
            "Dataset: Offcom2\n",
            "----------------------------------------\n",
            "MultinomialNB             | Acurácia: 0.6988 | F1: 0.6740\n",
            "RandomForestClassifier    | Acurácia: 0.6345 | F1: 0.6477\n",
            "LinearSVC                 | Acurácia: 0.6827 | F1: 0.6741\n",
            "LogisticRegression        | Acurácia: 0.6908 | F1: 0.6578\n",
            "KNeighborsClassifier      | Acurácia: 0.5301 | F1: 0.5413\n",
            "\n",
            "Dataset: OffcomBR-3\n",
            "----------------------------------------\n",
            "MultinomialNB             | Acurácia: 0.8204 | F1: 0.7522\n",
            "RandomForestClassifier    | Acurácia: 0.7864 | F1: 0.7628\n",
            "LinearSVC                 | Acurácia: 0.8010 | F1: 0.7591\n",
            "LogisticRegression        | Acurácia: 0.8155 | F1: 0.7327\n",
            "KNeighborsClassifier      | Acurácia: 0.7961 | F1: 0.7445\n",
            "\n",
            "Dataset: OLID-BR\n",
            "----------------------------------------\n",
            "MultinomialNB             | Acurácia: 0.7432 | F1: 0.7083\n",
            "RandomForestClassifier    | Acurácia: 0.7476 | F1: 0.7347\n",
            "LinearSVC                 | Acurácia: 0.7449 | F1: 0.7334\n",
            "LogisticRegression        | Acurácia: 0.7502 | F1: 0.7185\n",
            "KNeighborsClassifier      | Acurácia: 0.7193 | F1: 0.6643\n",
            "\n",
            "Dataset: BiToLD\n",
            "----------------------------------------\n",
            "MultinomialNB             | Acurácia: 0.7188 | F1: 0.7136\n",
            "RandomForestClassifier    | Acurácia: 0.7541 | F1: 0.7548\n",
            "LinearSVC                 | Acurácia: 0.7192 | F1: 0.7177\n",
            "LogisticRegression        | Acurácia: 0.7397 | F1: 0.7358\n",
            "KNeighborsClassifier      | Acurácia: 0.6245 | F1: 0.5856\n",
            "\n",
            "Dataset: MultiOffcomBR-3\n",
            "----------------------------------------\n",
            "MultinomialNB             | Acurácia: 0.8155 | F1: 0.7327\n",
            "RandomForestClassifier    | Acurácia: 0.7718 | F1: 0.7290\n",
            "LinearSVC                 | Acurácia: 0.8010 | F1: 0.7416\n",
            "LogisticRegression        | Acurácia: 0.8204 | F1: 0.7437\n",
            "KNeighborsClassifier      | Acurácia: 0.8155 | F1: 0.7423\n",
            "\n",
            "Resultados salvos em 'resultados_classificacao.csv'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import unicodedata\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import time\n",
        "\n",
        "# Download dos recursos do NLTK se necessário\n",
        "try:\n",
        "    from nltk.corpus import stopwords\n",
        "except ImportError:\n",
        "    import nltk\n",
        "    nltk.download('stopwords')\n",
        "    nltk.download('wordnet')\n",
        "    from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "def train_and_evaluate_classifiers(datasets_configs, classifiers):\n",
        "    \"\"\"\n",
        "    Treina e avalia múltiplos classificadores em múltiplos datasets\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "    \n",
        "    for dataset_config in datasets_configs:\n",
        "        dataset_name = dataset_config.get(\"name\", \"unknown_dataset\")\n",
        "        print(f\"\\n{'='*50}\")\n",
        "        print(f\"Processando dataset: {dataset_name}\")\n",
        "        print(f\"{'='*50}\")\n",
        "        \n",
        "        try:\n",
        "            # Carrega e prepara os dados\n",
        "            df = load_and_prepare_data(\n",
        "                dataset_config[\"filepath\"],\n",
        "                dataset_config[\"text_column\"],\n",
        "                dataset_config[\"label_column\"]\n",
        "            )\n",
        "            \n",
        "            # Divide os dados\n",
        "            text_train, text_test, label_train, label_test = split_data(df)\n",
        "            \n",
        "            # Vectorização TF-IDF (apenas uma vez por dataset)\n",
        "            tfidf_vectorizer = TfidfVectorizer(\n",
        "                min_df=5, \n",
        "                ngram_range=(1, 2),\n",
        "                max_features=10000\n",
        "            )\n",
        "            X_train = tfidf_vectorizer.fit_transform(text_train)\n",
        "            X_test = tfidf_vectorizer.transform(text_test)\n",
        "            print(f\"Vectorização concluída\")\n",
        "            \n",
        "            # Treina e avalia cada classificador\n",
        "            for classifier in classifiers:\n",
        "                classifier_name = classifier.__class__.__name__\n",
        "                print(f\"\\nTreinando {classifier_name}...\")\n",
        "                \n",
        "                # Treina o classificador\n",
        "                classifier.fit(X_train, label_train)\n",
        "                \n",
        "                # Faz predições\n",
        "                predictions = classifier.predict(X_test)\n",
        "                \n",
        "                # Calcula métricas\n",
        "                accuracy = accuracy_score(label_test, predictions)\n",
        "                f1 = f1_score(label_test, predictions, average='weighted')\n",
        "                \n",
        "                # Armazena resultados\n",
        "                if dataset_name not in results:\n",
        "                    results[dataset_name] = {}\n",
        "                \n",
        "                results[dataset_name][classifier_name] = {\n",
        "                    'accuracy': accuracy,\n",
        "                    'f1_score': f1,\n",
        "                    'model': classifier,\n",
        "                    'vectorizer': tfidf_vectorizer,\n",
        "                    'predictions': predictions,\n",
        "                    'true_labels': label_test.values\n",
        "                }\n",
        "                \n",
        "                print(f\"  Acurácia: {accuracy:.4f}\")\n",
        "                print(f\"  F1-Score: {f1:.4f}\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar dataset {dataset_name}: {str(e)}\")\n",
        "            continue\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Configurações dos datasets\n",
        "datasets = [\n",
        "    {  # HateBR\n",
        "        \"name\": \"HateBR\",\n",
        "        \"filepath\": datasets_paths[4],\n",
        "        \"text_column\": 'comentario',\n",
        "        \"label_column\": 'label_final'\n",
        "    },\n",
        "    {  # Offcom2\n",
        "        \"name\": \"Offcom2\",\n",
        "        \"filepath\": datasets_paths[2],\n",
        "        \"text_column\": 'comentario',\n",
        "        \"label_column\": 'label'\n",
        "    },\n",
        "    {  # OffcomBR-3\n",
        "        \"name\": \"OffcomBR-3\",\n",
        "        \"filepath\": datasets_paths[1],\n",
        "        \"text_column\": 'mensagem',\n",
        "        \"label_column\": 'label'\n",
        "    },\n",
        "    {  # OLID-BR \n",
        "        \"name\": \"OLID-BR\",\n",
        "        \"filepath\": datasets_paths[0],\n",
        "        \"text_column\": 'text',\n",
        "        \"label_column\": 'hatespeech_comb'\n",
        "    },\n",
        "    {  # BiToLD\n",
        "        \"name\": \"BiToLD\",\n",
        "        \"filepath\": datasets_paths[3],\n",
        "        \"text_column\": 'text',\n",
        "        \"label_column\": 'Discurso_de_odio'\n",
        "    },\n",
        "    {   # MultiOffcomBR-3\n",
        "        \"name\": \"MultiOffcomBR-3\",\n",
        "        \"filepath\": datasets_paths[5],\n",
        "        \"text_column\": 'mensagem',\n",
        "        \"label_column\": 'label_final'\n",
        "    },\n",
        "]\n",
        "\n",
        "# Classificadores (instanciados com parâmetros otimizados)\n",
        "classifiers = [\n",
        "    MultinomialNB(),\n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),\n",
        "    LinearSVC(random_state=42, max_iter=1000),\n",
        "    LogisticRegression(random_state=42, max_iter=1000, n_jobs=-1),\n",
        "    KNeighborsClassifier(n_jobs=-1)\n",
        "]\n",
        "\n",
        "# Executa treinamento e avaliação\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Iniciando processo de treinamento e avaliação...\")\n",
        "    results = train_and_evaluate_classifiers(datasets, classifiers)\n",
        "    \n",
        "    # Exibe resultados resumidos\n",
        "    print(\"\\n\\n\" + \"=\"*60)\n",
        "    print(\"RESUMO FINAL DOS RESULTADOS\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    for dataset_name, dataset_results in results.items():\n",
        "        print(f\"\\nDataset: {dataset_name}\")\n",
        "        print(\"-\" * 40)\n",
        "        for classifier_name, metrics in dataset_results.items():\n",
        "            print(f\"{classifier_name:25} | Acurácia: {metrics['accuracy']:.4f} | F1: {metrics['f1_score']:.4f}\")\n",
        "    \n",
        "    # Salva resultados em arquivo CSV\n",
        "    results_df = pd.DataFrame()\n",
        "    for dataset_name, dataset_results in results.items():\n",
        "        for classifier_name, metrics in dataset_results.items():\n",
        "            results_df = pd.concat([results_df, pd.DataFrame({\n",
        "                'Dataset': [dataset_name],\n",
        "                'Classificador': [classifier_name],\n",
        "                'Acurácia': [metrics['accuracy']],\n",
        "                'F1-Score': [metrics['f1_score']],\n",
        "            })], ignore_index=True)\n",
        "    \n",
        "    results_df.to_csv('resultados_classificacao.csv', index=False)\n",
        "    print(\"\\nResultados salvos em 'resultados_classificacao.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "KxuIyS-tVduo"
      },
      "outputs": [],
      "source": [
        "# 5. Analysis (Matriz)\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "predictions = []\n",
        "\n",
        "for dataset_config in datasets:\n",
        "    df = load_and_prepare_data(dataset_config[\"filepath\"],\n",
        "                               dataset_config[\"text_column\"],\n",
        "                               dataset_config[\"label_column\"])\n",
        "    \n",
        "    text_train, text_test, label_train, label_test = split_data(df)\n",
        "\n",
        "    vectorizer = TfidfVectorizer(min_df=5, ngram_range=(1, 2), max_features=10000)\n",
        "    X_train = vectorizer.fit_transform(text_train)\n",
        "    X_test = vectorizer.transform(text_test)\n",
        "\n",
        "    for classifier in classifiers:\n",
        "        classifier.fit(X_train, label_train)\n",
        "        y_pred = classifier.predict(X_test)\n",
        "        predictions.append({\n",
        "            \"dataset\": dataset_config[\"name\"],\n",
        "            \"classifier\": classifier.__class__.__name__,\n",
        "            \"label_test\": label_test,\n",
        "            \"y_pred\": y_pred\n",
        "            })\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # present_prediction = predictions[0]  # Exemplo: pegar a primeira predição para visualização\n",
        "    # dataset_name = present_prediction[\"dataset\"]\n",
        "    # classifier_name = present_prediction[\"classifier\"]\n",
        "\n",
        "    # label_test = present_prediction[\"label_test\"]\n",
        "    # y_pred = present_prediction[\"y_pred\"]\n",
        "\n",
        "    for prediction in predictions:\n",
        "        dataset_name = prediction[\"dataset\"]\n",
        "        classifier_name = prediction[\"classifier\"]\n",
        "        label_test = prediction[\"label_test\"]\n",
        "        y_pred = prediction[\"y_pred\"]\n",
        "\n",
        "        confusion_metrics = confusion_matrix(label_test, y_pred)\n",
        "\n",
        "        class_names = np.unique(np.concatenate((label_test, y_pred)))\n",
        "        sns.heatmap(confusion_metrics, annot=True, fmt='d', cmap='Greens', xticklabels=class_names, yticklabels=class_names)\n",
        "\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.ylabel('Actual Labels')\n",
        "        plt.xlabel('Predicted Labels')\n",
        "        plt.suptitle(f'Dataset: {dataset_name} | Classifier: {classifier_name}', fontsize=10)\n",
        "        swarm_plt = plt.gcf()\n",
        "        if not os.path.exists(\"Confusion_Matrix_Images\"):\n",
        "            os.mkdir(\"Confusion_Matrix_Images\")\n",
        "        \n",
        "        if os.path.exists(\"Confusion_Matrix_Images/confusion_matrix_{}_{}.png\".format(dataset_name, classifier_name)):\n",
        "            os.remove(\"Confusion_Matrix_Images/confusion_matrix_{}_{}.png\".format(dataset_name, classifier_name))\n",
        "        \n",
        "        swarm_plt.savefig(f'Confusion_Matrix_Images/confusion_matrix_{dataset_name}_{classifier_name}.png')\n",
        "        \n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "s8WI9I-qVDlx"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 4.2 Classification (Exemple Prediction) [0% ainda não testei nem estudei]\n",
        "teste = tfidf_vectorizer.transform([\"Você é um lindo\"])\n",
        "rf.predict(teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "iSellO1Klg54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 4.2 Classification (Exemple Prediction) [0% ainda não testei nem estudei]\n",
        "teste = tfidf_vectorizer.transform([\"Você é um lixo\"])\n",
        "rf.predict(teste)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
